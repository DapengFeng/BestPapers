<h2 class="wp-block-heading"><strong>Best Papers</strong></h2>



<h4 class="wp-block-heading"><strong>Split-Lohmann Multifocal Displays</strong></h4>



<p>This work describes a near-eye 3D display that instantaneously creates a virtual world, fully supporting the human eye’s native ability to focus on content placed at different distances. This capability enables a viewer to experience 3D videos and interactive games at a previously unattainable level of immersion.</p>



<p><em>Yingsi Qin, Wei-Yu Chen, Matthew O’Toole, Aswin C. Sankaranarayanan, Carnegie Mellon University</em></p>



<h4 class="wp-block-heading"><strong>Differentiable Stripe Patterns for Inverse Design of Structured Surfaces</strong></h4>



<p>We introduce Differentiable Stripe Patterns — a computational approach for automated design of physical surfaces structured with stripe-shaped, bi-material distributions. We propose a gradient-based optimization tool to automatically compute stripe patterns that best approximate macromechanical performance goals.</p>



<p><em>Juan Sebastian Montes Maestre, Yinwei Du, Ronan Hinchet, Stelian Coros, Bernhard Thomaszewski, ETH Zürich</em></p>



<h4 class="wp-block-heading"><strong>Globally Consistent Normal Orientation for Point Clouds by Regularizing the Winding-number Field</strong></h4>



<p>We propose a smooth objective function to characterize the requirements of an acceptable winding-number field, which allows one to find the globally consistent normal orientations starting from a set of completely random normals.</p>



<p><em>Rui Xu, Shandong University; Zhiyang Dou, The University of Hong Kong; Ningna Wang, The University of Texas at Dallas; Shiqing Xin, Shandong University; Shuangmin Chen, </em><em>Qingdao University of Science and Technology; Mingyan Jiang, Shandong University; Xiaohu Guo, The University of Texas at Dallas; Wenping Wang, Texas A&amp;M University; Changhe Tu, Shandong University</em></p>



<h4 class="wp-block-heading"><strong>3D Gaussian Splatting for Real-time Radiance Field Rendering</strong></h4>



<p>Our method allows real-time rendering (&gt;= 30fps) of radiance fields with high visual quality. We represent scenes accurately with 3D Gaussians allowing efficient optimization. Our visibility-aware rendering accelerates training which is as fast as the fastest previous methods for equivalent quality. An additional hour of training provides state-of-the-art quality.</p>



<p><em>Bernhard Kerbl, Inria, Université Côte d’Azur; Georgios Kopanas, Inria, Université Côte d’Azur; Thomas Leimkuehler, </em><em>Max-Planck-Institut für Informatik; George Drettakis, Inria, Université Côte d’Azur</em></p>



<h4 class="wp-block-heading"><strong>DOC: Differentiable Optimal Control for Retargeting Motions Onto Legged Robots</strong></h4>



<p>We present a Differentiable Optimal Control (DOC) framework that facilitates the computation of analytical derivatives of optimal control and state trajectories with respect to user-defined parameters. We demonstrate the utility of DOC by retargeting mocap and animation data onto a family of legged robots of varying proportions and mass distribution.</p>



<p><em>Ruben Grandia, Disney Research Imagineering; Farbod Farshidian, ETH Zürich; Espen Knoop, Disney Research Imagineering; Christian Schumacher, Disney Research Imagineering; Marco Hutter, ETH Zürich; Moritz Bächer, Disney Research Imagineering</em></p>



<h2 class="wp-block-heading"><strong>Honorable Mentions</strong></h2>



<h4 class="wp-block-heading"><strong>GestureDiffuCLIP: Gesture Diffusion Model With CLIP Latents</strong></h4>



<p>We introduce GestureDiffuCLIP, a CLIP-guided, co-speech gesture synthesis system that creates stylized gestures in harmony with speech semantics and rhythm using arbitrary style prompts. Our highly adaptable system supports style prompts in the form of short texts, motion sequences, or video clips and provides body part-specific style control.</p>



<p><em>Tenglong Ao, Zeyi Zhang, Libin Liu, Peking University</em></p>



<h4 class="wp-block-heading"><strong>Word-as-image for Semantic Typography</strong></h4>



<p>Word-as-image is a technique where a word illustration presents a visualization of the meaning of the word, while also preserving its readability. We present a method to create word-as-image illustrations automatically. We optimize the outline of each letter to convey the desired concept, guided by a pretrained Stable Diffusion model.</p>



<p><em>Shir Iluz, Tel Aviv University; Yael Vinker, Tel Aviv University; Amir Hertz, Tel Aviv University; Daniel Berio, Goldsmiths University of London; Daniel Cohen-Or, Tel Aviv University; Ariel Shamir, Reichman University</em></p>



<h4 class="wp-block-heading"><strong>Sag-Free Initialization for Strand-Based Hybrid Hair Simulation</strong></h4>



<p>This paper proposes a novel four-stage, sag-free initialization framework to solve stable quasistatic configurations for hybrid, strand-based hair dynamic systems. Our results show that our method successfully prevents sagging on various hairstyles and has minimal impact on the hair motion during simulation.</p>



<p><em>Jerry Hsu, University of Utah, LightSpeed Studios, Tencent America; Tongtong Wang, LightSpeed Studios, Tencent America; Zherong Pan, LightSpeed Studios, Tencent America; Xifeng Gao, LightSpeed Studios, Tencent America; Cem Yuksel, </em><em>University of Utah, Roblox Research; Kui Wu, LightSpeed Studios, Tencent America&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</em></p>



<h4 class="wp-block-heading"><strong>Deployable Strip Structures</strong></h4>



<p>C-meshes capture kinetic structures deployable from a collapsed state. They enjoy rich geometry and surprising relations to differential geometry, in particular surfaces with the linear Weingarten property. We provide tools for designing and exploring the shape space of C-meshes, and we present architectural paneling applications.</p>



<p><em>Daoming Liu, King Abdullah University of Science and Technology (KAUST); Davide Pellis, ISTI-CNR; Yu-Chou Chiang, National Chung Hsing University; Florian Rist, King Abdullah University of Science and Technology (KAUST); Johannes Wallner, TU Graz; Helmut Pottmann, King Abdullah University of Science and Technology (KAUST)</em></p>



<h4 class="wp-block-heading"><strong>Towards Attention-Aware Rendering</strong></h4>



<p>Existing perceptual models used in foveated graphics neglect the effects of visual attention. We introduce the first attention-aware model of contrast sensitivity and motivate the development of future foveation models, demonstrating that tolerance for foveation is significantly higher when the user is concentrating on a task in the fovea.</p>



<p><em>Brooke Krajancich, </em><em>Stanford University; Petr Kellnhofer, TU Delft; Gordon Wetzstein, Stanford University</em></p>



<h4 class="wp-block-heading"><strong>Random-access Neural Compression of Material Textures</strong></h4>



<p>This work introduces a neural compression technique for mipmapped material texture sets, offering significantly better compression than BCx at comparable quality and even surpassing entropy-coded AVIF and JPEG XL at low bitrates. Our method uses small, optimized neural networks for efficient compression, real-time decompression, and random access on GPUs.</p>



<p><em>Karthik Vaidyanathan, Marco Salvi, Bartlomiej Wronski, Tomas Akenine-Moller, Pontus Ebelin, Aaron Lefohn, NVIDIA</em></p>



<h4 class="wp-block-heading"><strong>Learning Physically Simulated Tennis Skills From Broadcast Videos</strong></h4>



<p>We present a system to learn diverse and complex tennis skills leveraging large-scale but lower-quality motions harvested from broadcast tennis videos for physically simulated characters to hit the ball to target positions with high accuracy and successfully conduct competitive rally play that includes a range of shot types and spins.</p>



<p><em>Haotian Zhang, Stanford University; Ye Yuan, NVIDIA; Viktor Makoviychuk, NVIDIA; Yunrong Guo, NVIDIA; Sanja Fidler, NVIDIA, University of Toronto; Xue Bin Peng, NVIDIA, Simon Fraser University; Kayvon Fatahalian, Stanford University</em></p>



<h4 class="wp-block-heading"><strong>Min-Deviation-Flow in Bi-directed Graphs for T-Mesh Quantization</strong></h4>



<p>Integer optimization problems for T-mesh quantization are central to state-of-the-art quad-meshing methods. We show how their structure allows modeling as generalized network flow problems in multiple ways. Our novel approximate and exact solvers achieve dramatic speed-ups over general solvers and have applications beyond T-mesh quantization.</p>



<p><em>Martin Heistermann, University of Bern; Jethro Warnett, University of Oxford; David Bommes, University of Bern</em></p>



<h2 class="wp-block-heading"><strong>Test-of-Time Awards</strong></h2>



<p>ACM SIGGRAPH is delighted to announce the 2023 Test-of-Time Award papers that have had a significant and lasting impact on computer graphics and interactive techniques over at least a decade. This is the first year of this annual award. For 2023, the papers presented at SIGGRAPH conferences from 2011 to 2013 were considered by the Test-of-Time Award committee and the committee selected four winning papers.</p>



<h4 class="wp-block-heading"><strong>Functional Maps: A Flexible Representation of Maps Between Shapes (2012)</strong></h4>



<p>Establishing correspondences between pairs of shapes is a fundamental step for shape inference and manipulation. This paper introduced a new representation of functional maps and has sparked a large volume of follow-on research on shape matching. <a href="https://doi.org/10.1145/2185520.2185526" target="_blank" rel="noreferrer noopener">Read the paper on the ACM Digital Library</a>.</p>



<p><em>Maks Ovsjanikov, Mirela Ben-Chen, Justin Solomon, Adrian Butscher, Leonidas Guibas</em><em></em></p>



<h4 class="wp-block-heading"><strong>Eulerian Video Magnification for Revealing Subtle Changes in the World (2012)</strong></h4>



<p>This paper shows that cameras can capture subtle, yet important, motion that is too subtle for the human eye to see. Follow-on studies have found many application areas including video surveillance, visual vibrometry, and visual microphones. <a href="https://doi.org/10.1145/2185520.2185561" target="_blank" rel="noreferrer noopener">Read the paper on the ACM Digital Library</a>.</p>



<p><em>Hao-Yu Wu, Michael Rubinstein, Eugene Shih, John Guttag, Frédo Durand, William Freeman</em><em></em></p>



<h4 class="wp-block-heading"><strong>HDR-VDP-2: A Calibrated Visual Metric for Visibility and Quality Predictions in All Luminance Conditions (2011)</strong></h4>



<p>The metric presented in this paper includes a calibrated model of human vision across different luminance conditions and has become the default standard metric to predict the visibility and quality of images for a wide range of intensities.&nbsp;<a href="https://doi.org/10.1145/2010324.1964935" target="_blank" rel="noreferrer noopener">Read the paper on the ACM Digital Library</a>.</p>



<p><em>Rafal Mantiuk, Kil Joong Kim, Allan G. Rempel, Wolfgang Heidrich</em><em></em></p>



<h4 class="wp-block-heading"><strong>Optimizing Locomotion Controllers Using Biologically-based Actuators and Objectives (2012)</strong></h4>



<p>This paper introduced an innovative way to simulate human locomotion at the musculoskeletal level and inspired new research directions in how we view human movements and the extent to which they can be simulated. <a href="https://doi.org/10.1145/2185520.2185521" target="_blank" rel="noreferrer noopener">Read the paper on the ACM Digital Library</a>.</p>



<p><em>Jack M. Wang, Samuel R. Hamner, Scott L. Delp, Vladlen Koltun</em><em></em></p>
